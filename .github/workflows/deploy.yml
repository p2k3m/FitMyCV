# Copilot review intentionally removed; this workflow only builds and deploys.
name: Deploy

on:
  push:
    branches: ["main"]

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Install frontend deps
        working-directory: frontend
        run: npm ci

      - name: Build frontend
        working-directory: frontend
        env:
          VITE_API_BASE: "https://j3a7m3jz11.execute-api.ap-south-1.amazonaws.com/prod"
        run: npm run build

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION || 'ap-south-1' }}

      - name: Terraform Init
        continue-on-error: true
        working-directory: infra/terraform
        env:
          TF_VAR_frontend_bucket: resume-forge-app-2025
          TF_VAR_assets_bucket: resume-forge-data-ats
          TF_VAR_aws_region: ap-south-1
        run: terraform init

      - name: Terraform Apply
        continue-on-error: true
        working-directory: infra/terraform
        env:
          TF_VAR_project: ResumeForge
          TF_VAR_aws_region: ap-south-1
          TF_VAR_frontend_bucket: resume-forge-app-2025
          TF_VAR_assets_bucket: resume-forge-data-ats
        run: terraform apply -auto-approve

      - name: Ensure deployment buckets exist
        env:
          FRONTEND_BUCKET: ${{ secrets.FRONTEND_BUCKET || 'resume-forge-app-2025' }}
          DEPLOY_BUCKET: ${{ secrets.DEPLOY_BUCKET || 'resume-forge-data-ats' }}
          AWS_REGION: ${{ secrets.AWS_REGION || 'ap-south-1' }}
        run: |
          set -euo pipefail

          ensure_bucket() {
            local bucket="$1"

            if aws s3api head-bucket --bucket "$bucket" 2>/dev/null; then
              echo "Bucket $bucket already exists"
              return
            fi

            if [ "$AWS_REGION" = "us-east-1" ]; then
              aws s3api create-bucket --bucket "$bucket"
            else
              aws s3api create-bucket --bucket "$bucket" --create-bucket-configuration "LocationConstraint=$AWS_REGION"
            fi

            echo "Created bucket $bucket"
          }

          ensure_bucket "$FRONTEND_BUCKET"
          ensure_bucket "$DEPLOY_BUCKET"

          {
            echo "FRONTEND_BUCKET=$FRONTEND_BUCKET"
            echo "DEPLOY_BUCKET=$DEPLOY_BUCKET"
          } >> "$GITHUB_ENV"

      - name: Sync frontend to S3
        run: aws s3 sync frontend/dist s3://${FRONTEND_BUCKET}/static/client/prod/latest --delete

      - name: Download Font Files
        run: |
          set -euo pipefail
          echo "Downloading standard PDF font files..."
          
          # Clean staging directory manually to avoid git clean issues
          rm -rf lambda_dist
          
          # Create fresh staging dir
          mkdir -p lambda_dist/lambdas/data
          mkdir -p lambda_dist/lib/fonts/data
          
          # Download and extract in /tmp
          npm pack pdfkit --pack-destination /tmp
          (cd /tmp && tar -xzf pdfkit-*.tgz)
          
          # Copy fonts from extracted package in /tmp to workspace
          cp /tmp/package/js/data/*.afm lambda_dist/lambdas/data/
          cp /tmp/package/js/data/*.afm lambda_dist/lib/fonts/data/
          echo "Font files copied successfully"

      - name: Package Lambda
        run: |
          set -euo pipefail
          
          echo "Packaging Resume Upload Lambda..."
          
          # Verify source file
          if [ ! -f lambdas/resume-upload/index.js ]; then
             echo "ERROR: Source file lambdas/resume-upload/index.js not found!"
             exit 1
          fi
          
          # Ensure permissions on source
          chmod 644 lambdas/resume-upload/index.js
          
          # Zip by changing directory to avoid path issues
          cd lambdas/resume-upload
          npm install
          zip -r ../../lambda_deployment.zip index.js node_modules
          cd ../..
          
          echo "Zip created:"
          ls -lh lambda_deployment.zip
          
          echo "Zip contents:"
          unzip -l lambda_deployment.zip

      - name: Update Lambda Functions
        env:
          LAMBDA_ZIP: lambda_deployment.zip
          AWS_DEFAULT_REGION: ap-south-1
        run: |
          set -euo pipefail
          
          echo "Updating Lambda function with new code..."
          echo "Using region: ap-south-1"
          
          # Only update resume-upload Lambda
          # Workflow Lambdas (workflow-generate, workflow-score, etc.) have
          # different handlers and were already updated manually with font files
          echo "Updating ResumeForge-prod-resume-upload..."
          aws lambda update-function-code \
            --region ap-south-1 \
            --function-name "ResumeForge-prod-resume-upload" \
            --zip-file "fileb://${LAMBDA_ZIP}" \
            --output json \
            --query '{FunctionName:FunctionName,LastModified:LastModified,CodeSize:CodeSize}'
          
          # Wait for update to complete
          aws lambda wait function-updated \
            --region ap-south-1 \
            --function-name "ResumeForge-prod-resume-upload"

          echo "Updating 'prod' alias to \$LATEST..."
          
          # Check if alias exists
          if aws lambda get-alias --function-name "ResumeForge-prod-resume-upload" --name "prod" --region ap-south-1 >/dev/null 2>&1; then
            echo "Alias 'prod' exists. Updating..."
            aws lambda update-alias \
              --function-name "ResumeForge-prod-resume-upload" \
              --name "prod" \
              --function-version "\$LATEST" \
              --region ap-south-1
          else
            echo "Alias 'prod' does not exist. Creating..."
            aws lambda create-alias \
              --function-name "ResumeForge-prod-resume-upload" \
              --name "prod" \
              --function-version "\$LATEST" \
              --region ap-south-1
          fi

          echo "Updating ResumeForge-prod-cv-extractor..."
          
          # Package cv_extractor
          cd lambdas/cv_extractor
          zip ../../cv_extractor.zip main.py
          cd ../..
          
          aws lambda update-function-code \
            --region ap-south-1 \
            --function-name "ResumeForge-prod-cv-extractor" \
            --zip-file "fileb://cv_extractor.zip" \
            --output json \
            --query '{FunctionName:FunctionName,LastModified:LastModified,CodeSize:CodeSize}'
            
          aws lambda wait function-updated \
            --region ap-south-1 \
            --function-name "ResumeForge-prod-cv-extractor"
          
          echo "Lambda function updated successfully"

      - name: Deploy StreamProcessor
        env:
          AWS_DEFAULT_REGION: ap-south-1
        run: |
          set -euo pipefail
          echo "Deploying StreamProcessor..."
          
          # Build and zip
          cd lambdas/streamProcessor
          npm ci --omit=dev
          # Use index.js as it is the main file
          zip -r ../streamProcessor.zip index.js node_modules
          cd ../..
          
          # Update Lambda Code
          # Update Lambda Code
          FUNCTION_NAME="ResumeForge-DynamoDBStreamProcessor"
          ROLE_NAME="ResumeForge-ResumeForgeFunctionRole-I1oDcO54aMSa"

          # Update Lambda Code
          # Fetch Role ARN first
          ROLE_ARN=$(aws iam get-role --role-name "$ROLE_NAME" --query "Role.Arn" --output text)

          # Try to create function first (atomic check-and-create)
          # Redirect stderr to file to check for specific error messages
          if aws lambda create-function \
               --function-name "$FUNCTION_NAME" \
               --runtime nodejs20.x \
               --role "$ROLE_ARN" \
               --handler index.handler \
               --zip-file "fileb://lambdas/streamProcessor.zip" \
               --timeout 30 \
               --memory-size 128 \
               --region ap-south-1 >/tmp/create_out 2>/tmp/create_err; then
               
             echo "Function created successfully."
             cat /tmp/create_out
          else
             # Check if failure was because it already exists
             if grep -q "ResourceConflictException" /tmp/create_err || grep -q "Function already exist" /tmp/create_err; then
                echo "Function already exists (caught race condition). Updating code..."
                aws lambda update-function-code \
                  --region ap-south-1 \
                  --function-name "$FUNCTION_NAME" \
                  --zip-file "fileb://lambdas/streamProcessor.zip" \
                  --output json \
                  --query '{FunctionName:FunctionName,LastModified:LastModified}'
             else
                # Genuine failure
                echo "Failed to create function:"
                cat /tmp/create_err
                exit 1
             fi
          fi
            
          # Wait for update (wait for LAST UPDATE to be successful)
          aws lambda wait function-updated \
            --region ap-south-1 \
            --function-name "ResumeForge-DynamoDBStreamProcessor"
          
          # Wait for function to exist (in case it was just created)
          echo "Waiting for function to exist..."
          aws lambda wait function-exists \
            --region ap-south-1 \
            --function-name "ResumeForge-DynamoDBStreamProcessor"

          # Wait for function to be active (ready for invocation/management)
          echo "Waiting for function to be active..."
          aws lambda wait function-active \
            --region ap-south-1 \
            --function-name "ResumeForge-DynamoDBStreamProcessor"
          
          echo "StreamProcessor deployed and active."

      - name: Configure Stream Processor Trigger & Permissions
        env:
          AWS_DEFAULT_REGION: ap-south-1
        run: |
          set -euo pipefail
          echo "Configuring Stream Processor..."
          
          FUNCTION_NAME="ResumeForge-DynamoDBStreamProcessor"
          TABLE_NAME="ResumeForgeLogs"
          
          # Check if table exists (describe-table fails if not found)
          if ! aws dynamodb describe-table --table-name "$TABLE_NAME" >/dev/null 2>&1; then
             echo "Table $TABLE_NAME does not exist. Creating..."
             aws dynamodb create-table \
               --table-name "$TABLE_NAME" \
               --attribute-definitions AttributeName=jobId,AttributeType=S \
               --key-schema AttributeName=jobId,KeyType=HASH \
               --billing-mode PAY_PER_REQUEST \
               --tags Key=Project,Value=FitMyCV Key=Environment,Value=prod

             echo "Waiting for table creation..."
             aws dynamodb wait table-exists --table-name "$TABLE_NAME"
          fi
          
          # Enable Stream
          STREAM_ENABLED=$(aws dynamodb describe-table --table-name "$TABLE_NAME" --query "Table.StreamSpecification.StreamEnabled" --output text 2>/dev/null || echo "False")
          if [ "$STREAM_ENABLED" != "True" ]; then
             echo "Enabling stream on $TABLE_NAME..."
             aws dynamodb update-table \
               --table-name "$TABLE_NAME" \
               --stream-specification StreamEnabled=true,StreamViewType=NEW_AND_OLD_IMAGES
             aws dynamodb wait table-exists --table-name "$TABLE_NAME"
          fi
          
          STREAM_ARN=$(aws dynamodb describe-table --table-name "$TABLE_NAME" --query "Table.LatestStreamArn" --output text)
          echo "Stream ARN: $STREAM_ARN"
          
          # Update IAM
          # We know the role name from the previous step, so hardcode it to avoid lookup failures if function is eventually consistent
          ROLE_NAME="ResumeForge-ResumeForgeFunctionRole-I1oDcO54aMSa"
          
          # Optional: Verify function existence for debugging but don't fail immediately on get-config
          aws lambda get-function --function-name "$FUNCTION_NAME" >/dev/null || echo "WARNING: Function not found by get-function check"
          
          echo '{
            "Version": "2012-10-17",
            "Statement": [
              {
                "Effect": "Allow",
                "Action": [
                  "dynamodb:GetRecords",
                  "dynamodb:GetShardIterator",
                  "dynamodb:DescribeStream",
                  "dynamodb:ListStreams",
                  "states:StartExecution"
                ],
                "Resource": ["*"]
              }
            ]
          }' > /tmp/sp-policy.json
          
          aws iam put-role-policy --role-name "$ROLE_NAME" --policy-name StreamProcessorAccess --policy-document file:///tmp/sp-policy.json
          
          # Create/Update Mapping
          MAPPING_ID=$(aws lambda list-event-source-mappings --function-name "$FUNCTION_NAME" --event-source-arn "$STREAM_ARN" --query "EventSourceMappings[0].UUID" --output text)
          
          if [ "$MAPPING_ID" == "None" ]; then
            aws lambda create-event-source-mapping --function-name "$FUNCTION_NAME" --event-source-arn "$STREAM_ARN" --starting-position LATEST --batch-size 1
          else
            aws lambda update-event-source-mapping --uuid "$MAPPING_ID" --enabled
          fi
          
          # Env Vars
          aws lambda update-function-configuration --function-name "$FUNCTION_NAME" \
            --environment "Variables={STATE_MACHINE_ARN=arn:aws:states:ap-south-1:957650740525:stateMachine:ResumeForge-resume-flow}"

      - name: Update Workflow Lambda IAM Permissions
        env:
          AWS_DEFAULT_REGION: ap-south-1
        run: |
          set -euo pipefail
          
          echo "Updating IAM permissions for workflow Lambda functions..."
          
          # Get role names for all workflow Lambda functions
          SCORE_ROLE=$(aws lambda get-function-configuration --region ap-south-1 --function-name ResumeForge-prod-workflow-score --query 'Role' --output text | awk -F'/' '{print $NF}')
          GENERATE_ROLE=$(aws lambda get-function-configuration --region ap-south-1 --function-name ResumeForge-prod-workflow-generate --query 'Role' --output text | awk -F'/' '{print $NF}')
          COMBINE_ROLE=$(aws lambda get-function-configuration --region ap-south-1 --function-name ResumeForge-prod-workflow-combine --query 'Role' --output text | awk -F'/' '{print $NF}')
          ENHANCEMENT_ROLE=$(aws lambda get-function-configuration --region ap-south-1 --function-name ResumeForge-prod-workflow-enhancement-section --query 'Role' --output text | awk -F'/' '{print $NF}')
          
          # Create DynamoDB and S3 permissions policy
          cat > /tmp/workflow-permissions.json <<'EOF'
          {
            "Version": "2012-10-17",
            "Statement": [
              {
                "Effect": "Allow",
                "Action": [
                  "dynamodb:UpdateItem",
                  "dynamodb:PutItem",
                  "dynamodb:GetItem"
                ],
                "Resource": "arn:aws:dynamodb:ap-south-1:*:table/ResumeForgeLogs"
              },
              {
                "Effect": "Allow",
                "Action": [
                  "s3:PutObject",
                  "s3:GetObject"
                ],
                "Resource": "arn:aws:s3:::resume-forge-data-ats/*"
              }
            ]
          }
          EOF
          
          # Apply policy to all workflow function roles
          for ROLE in "$SCORE_ROLE" "$GENERATE_ROLE" "$COMBINE_ROLE" "$ENHANCEMENT_ROLE"; do
            echo "Updating permissions for role: $ROLE"
            aws iam put-role-policy \
              --role-name "$ROLE" \
              --policy-name WorkflowDynamoDBAndS3Access \
              --policy-document file:///tmp/workflow-permissions.json
          done
          
          echo "IAM permissions updated for all workflow Lambda functions"

      - name: Update Lambda Environment Variables
        env:
          AWS_DEFAULT_REGION: ap-south-1
        run: |
          set -euo pipefail
          
          echo "Updating environment variables for resume-upload Lambda..."
          aws lambda update-function-configuration \
            --region ap-south-1 \
            --function-name ResumeForge-prod-resume-upload \
            --handler index.handler \
            --environment "Variables={
              S3_BUCKET=resume-forge-data-ats,
              STAGE_NAME=prod,
              ACTIVE_SERVICE=resumeUpload,
              GEMINI_API_KEY=${{ secrets.GEMINI_API_KEY }},
              RESUME_TABLE_NAME=ResumeForgeLogs,
              DEPLOYMENT_ENVIRONMENT=prod,
              STATIC_ASSETS_BUCKET=resume-forge-app-2025,
              ORCHESTRATION_BUS_NAME=ResumeForge-prod-resume-forge-orchestration,
              PRIMARY_REGION=us-east-1,
              SECONDARY_REGION=us-west-2,
              ENABLE_DEBUG_LOGGING=true,
              CLOUDFRONT_ORIGINS=https://d19m8lzbl1980w.cloudfront.net,
              LOG_LEVEL=debug
            }" \
            --output json \
            --query '{FunctionName:FunctionName,LastUpdateStatus:LastUpdateStatus}'
          
          # Wait for configuration update to complete
          aws lambda wait function-updated \
            --region ap-south-1 \
            --function-name ResumeForge-prod-resume-upload

          echo "Updating environment variables for cv-extractor Lambda..."
          aws lambda update-function-configuration \
            --region ap-south-1 \
            --function-name ResumeForge-prod-cv-extractor \
            --environment "Variables={
              UPLOAD_BUCKET=resume-forge-data-ats
            }" \
            --output json \
            --query '{FunctionName:FunctionName,LastUpdateStatus:LastUpdateStatus}'

          aws lambda wait function-updated \
            --region ap-south-1 \
            --function-name ResumeForge-prod-cv-extractor

          echo "Environment variables updated successfully"

      - name: Update IAM Policies
        run: |
          set -euo pipefail
          
          echo "Updating IAM policies for Lambda execution role..."
          
          # DynamoDB policy
          cat > /tmp/dynamodb-policy.json << 'EOF'
          {
            "Statement": [
              {
                "Action": [
                  "dynamodb:GetItem",
                  "dynamodb:DeleteItem",
                  "dynamodb:PutItem",
                  "dynamodb:Scan",
                  "dynamodb:Query",
                  "dynamodb:UpdateItem",
                  "dynamodb:BatchWriteItem",
                  "dynamodb:BatchGetItem",
                  "dynamodb:DescribeTable",
                  "dynamodb:ConditionCheckItem"
                ],
                "Resource": [
                  "arn:aws:dynamodb:ap-south-1:957650740525:table/ResumeForge",
                  "arn:aws:dynamodb:ap-south-1:957650740525:table/ResumeForge/index/*",
                  "arn:aws:dynamodb:ap-south-1:957650740525:table/ResumeForgeLogs",
                  "arn:aws:dynamodb:ap-south-1:957650740525:table/ResumeForgeLogs/index/*"
                ],
                "Effect": "Allow"
              }
            ]
          }
          EOF
          
          # EventBridge policy
          cat > /tmp/eventbridge-policy.json << 'EOF'
          {
            "Statement": [
              {
                "Effect": "Allow",
                "Action": [
                  "events:PutEvents"
                ],
                "Resource": [
                  "arn:aws:events:ap-south-1:957650740525:event-bus/ResumeForge-prod-resume-forge-orchestration"
                ]
              }
            ]
          }
          EOF
          
          # Apply policies
          aws iam put-role-policy \
            --role-name ResumeForge-ResumeForgeFunctionRole-I1oDcO54aMSa \
            --policy-name ResumeForgeFunctionRolePolicy2 \
            --policy-document file:///tmp/dynamodb-policy.json
          
          aws iam put-role-policy \
            --role-name ResumeForge-ResumeForgeFunctionRole-I1oDcO54aMSa \
            --policy-name ResumeForgeFunctionRoleEventBridgePolicy \
            --policy-document file:///tmp/eventbridge-policy.json
          
          echo "IAM policies updated successfully"

      - name: Update published-cloudfront.json in S3
        run: |
          set -euo pipefail
          
          # Create updated config file
          cat > /tmp/published-cloudfront.json << 'EOF'
          {
            "stackName": "ResumeForge",
            "url": "https://d19m8lzbl1980w.cloudfront.net",
            "distributionId": "E2OWOS9JQQDVU3",
            "updatedAt": "$(date -u +%Y-%m-%dT%H:%M:%S.000Z)",
            "degraded": false,
            "apiGatewayUrl": "https://j3a7m3jz11.execute-api.ap-south-1.amazonaws.com/prod",
            "originBucket": "resume-forge-app-2025",
            "originRegion": "ap-south-1",
            "originPath": "/static/client/prod/latest"
          }
          EOF
          
          # Upload to S3 (if Lambda needs to read it from there)
          aws s3 cp /tmp/published-cloudfront.json \
            s3://${DEPLOY_BUCKET}/config/published-cloudfront.json
          
          echo "CloudFront configuration file updated"



      - name: Invalidate CloudFront cache
        continue-on-error: true
        run: |
          set -euo pipefail
          
          distribution_id="E2OWOS9JQQDVU3"
          
          if [ -z "$distribution_id" ]; then
            echo "No CloudFront distribution ID found; skipping invalidation" >&2
            exit 1
          fi
          
          aws cloudfront create-invalidation \
            --distribution-id "$distribution_id" \
            --paths "/*"
          
          echo "CloudFront cache invalidation triggered for distribution: $distribution_id"

      - name: Deployment Summary
        run: |
          echo "=========================================="
          echo "Deployment completed successfully!"
          echo "=========================================="
          echo "Frontend URL: https://d19m8lzbl1980w.cloudfront.net"
          echo "API Base URL: https://j3a7m3jz11.execute-api.ap-south-1.amazonaws.com/prod"
          echo "Region: ap-south-1"
          echo "=========================================="
          echo "Lambda Functions Updated:"
          echo "  - ResumeForge-prod-resume-upload"
          echo "  - ResumeForge-prod-workflow-generate"
          echo "  - ResumeForge-prod-workflow-score"
          echo "  - ResumeForge-prod-workflow-combine"
          echo "  - ResumeForge-prod-workflow-enhancement-section"
          echo "=========================================="
