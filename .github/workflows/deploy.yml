# Copilot review intentionally removed; this workflow only builds and deploys.
name: Deploy

on:
  push:
    branches: ["main"]

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Install frontend deps
        working-directory: frontend
        run: npm ci

      - name: Build frontend
        working-directory: frontend
        env:
          VITE_API_BASE: "https://j3a7m3jz11.execute-api.ap-south-1.amazonaws.com/prod"
        run: npm run build

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION || 'ap-south-1' }}

      - name: Ensure deployment buckets exist
        env:
          FRONTEND_BUCKET: ${{ secrets.FRONTEND_BUCKET || 'resume-forge-app-2025' }}
          DEPLOY_BUCKET: ${{ secrets.DEPLOY_BUCKET || 'resume-forge-data-ats' }}
          AWS_REGION: ${{ secrets.AWS_REGION || 'ap-south-1' }}
        run: |
          set -euo pipefail

          ensure_bucket() {
            local bucket="$1"

            if aws s3api head-bucket --bucket "$bucket" 2>/dev/null; then
              echo "Bucket $bucket already exists"
              return
            fi

            if [ "$AWS_REGION" = "us-east-1" ]; then
              aws s3api create-bucket --bucket "$bucket"
            else
              aws s3api create-bucket --bucket "$bucket" --create-bucket-configuration "LocationConstraint=$AWS_REGION"
            fi

            echo "Created bucket $bucket"
          }

          ensure_bucket "$FRONTEND_BUCKET"
          ensure_bucket "$DEPLOY_BUCKET"

          {
            echo "FRONTEND_BUCKET=$FRONTEND_BUCKET"
            echo "DEPLOY_BUCKET=$DEPLOY_BUCKET"
          } >> "$GITHUB_ENV"

      - name: Sync frontend to S3
        run: aws s3 sync frontend/dist s3://${FRONTEND_BUCKET}/static/client/prod/latest --delete

      - name: Download Font Files
        run: |
          set -euo pipefail
          echo "Downloading standard PDF font files..."
          npm pack pdfkit --pack-destination /tmp
          cd /tmp && tar -xzf pdfkit-*.tgz
          mkdir -p lambda_extracted/lambdas/data
          mkdir -p lambda_extracted/lib/fonts/data
          cp package/js/data/*.afm lambda_extracted/lambdas/data/
          cp package/js/data/*.afm lambda_extracted/lib/fonts/data/
          echo "Font files copied successfully"

      - name: Package Lambda with Fonts
        run: |
          set -euo pipefail
          # Copy the resume-upload code into the staging directory
          cp lambdas/resume-upload/index.js lambda_extracted/index.js
          
          cd lambda_extracted
          zip -r ../lambda_deployment.zip .
          cd ..
          ls -lh lambda_deployment.zip

      - name: Update Lambda Functions
        env:
          LAMBDA_ZIP: lambda_deployment.zip
          AWS_DEFAULT_REGION: ap-south-1
        run: |
          set -euo pipefail
          
          echo "Updating Lambda function with new code..."
          echo "Using region: ap-south-1"
          
          # Only update resume-upload Lambda
          # Workflow Lambdas (workflow-generate, workflow-score, etc.) have
          # different handlers and were already updated manually with font files
          echo "Updating ResumeForge-prod-resume-upload..."
          aws lambda update-function-code \
            --region ap-south-1 \
            --function-name "ResumeForge-prod-resume-upload" \
            --zip-file "fileb://${LAMBDA_ZIP}" \
            --output json \
            --query '{FunctionName:FunctionName,LastModified:LastModified,CodeSize:CodeSize}'
          
          # Wait for update to complete
          aws lambda wait function-updated \
            --region ap-south-1 \
            --function-name "ResumeForge-prod-resume-upload"
          
          echo "Lambda function updated successfully"

      - name: Deploy StreamProcessor
        env:
          AWS_DEFAULT_REGION: ap-south-1
        run: |
          set -euo pipefail
          echo "Deploying StreamProcessor..."
          
          # Build and zip
          cd lambdas/streamProcessor
          npm ci --omit=dev
          # Use index.js as it is the main file
          zip -r ../streamProcessor.zip index.js node_modules
          cd ../..
          
          # Update Lambda Code
          aws lambda update-function-code \
            --region ap-south-1 \
            --function-name "ResumeForge-DynamoDBStreamProcessor" \
            --zip-file "fileb://lambdas/streamProcessor.zip" \
            --output json \
            --query '{FunctionName:FunctionName,LastModified:LastModified}'
            
          # Wait for update
          aws lambda wait function-updated \
            --region ap-south-1 \
            --function-name "ResumeForge-DynamoDBStreamProcessor"
          
          echo "StreamProcessor deployed successfully"

      - name: Update Workflow Lambda IAM Permissions
        env:
          AWS_DEFAULT_REGION: ap-south-1
        run: |
          set -euo pipefail
          
          echo "Updating IAM permissions for workflow Lambda functions..."
          
          # Get role names for all workflow Lambda functions
          SCORE_ROLE=$(aws lambda get-function-configuration --region ap-south-1 --function-name ResumeForge-prod-workflow-score --query 'Role' --output text | awk -F'/' '{print $NF}')
          GENERATE_ROLE=$(aws lambda get-function-configuration --region ap-south-1 --function-name ResumeForge-prod-workflow-generate --query 'Role' --output text | awk -F'/' '{print $NF}')
          COMBINE_ROLE=$(aws lambda get-function-configuration --region ap-south-1 --function-name ResumeForge-prod-workflow-combine --query 'Role' --output text | awk -F'/' '{print $NF}')
          ENHANCEMENT_ROLE=$(aws lambda get-function-configuration --region ap-south-1 --function-name ResumeForge-prod-workflow-enhancement-section --query 'Role' --output text | awk -F'/' '{print $NF}')
          
          # Create DynamoDB and S3 permissions policy
          cat > /tmp/workflow-permissions.json <<'EOF'
          {
            "Version": "2012-10-17",
            "Statement": [
              {
                "Effect": "Allow",
                "Action": [
                  "dynamodb:UpdateItem",
                  "dynamodb:PutItem",
                  "dynamodb:GetItem"
                ],
                "Resource": "arn:aws:dynamodb:ap-south-1:*:table/ResumeForgeLogs"
              },
              {
                "Effect": "Allow",
                "Action": [
                  "s3:PutObject",
                  "s3:GetObject"
                ],
                "Resource": "arn:aws:s3:::resume-forge-data-ats/*"
              }
            ]
          }
          EOF
          
          # Apply policy to all workflow function roles
          for ROLE in "$SCORE_ROLE" "$GENERATE_ROLE" "$COMBINE_ROLE" "$ENHANCEMENT_ROLE"; do
            echo "Updating permissions for role: $ROLE"
            aws iam put-role-policy \
              --role-name "$ROLE" \
              --policy-name WorkflowDynamoDBAndS3Access \
              --policy-document file:///tmp/workflow-permissions.json
          done
          
          echo "IAM permissions updated for all workflow Lambda functions"

      - name: Update Lambda Environment Variables
        env:
          AWS_DEFAULT_REGION: ap-south-1
        run: |
          set -euo pipefail
          
          echo "Updating environment variables for resume-upload Lambda..."
          aws lambda update-function-configuration \
            --region ap-south-1 \
            --function-name ResumeForge-prod-resume-upload \
            --environment "Variables={
              S3_BUCKET=resume-forge-data-ats,
              STAGE_NAME=prod,
              ACTIVE_SERVICE=resumeUpload,
              GEMINI_API_KEY=${{ secrets.GEMINI_API_KEY }},
              RESUME_TABLE_NAME=ResumeForgeLogs,
              DEPLOYMENT_ENVIRONMENT=prod,
              STATIC_ASSETS_BUCKET=resume-forge-app-2025,
              ORCHESTRATION_BUS_NAME=ResumeForge-prod-resume-forge-orchestration,
              PRIMARY_REGION=us-east-1,
              SECONDARY_REGION=us-west-2,
              ENABLE_DEBUG_LOGGING=true,
              CLOUDFRONT_ORIGINS=https://d19m8lzbl1980w.cloudfront.net,
              LOG_LEVEL=debug
            }" \
            --output json \
            --query '{FunctionName:FunctionName,LastUpdateStatus:LastUpdateStatus}'
          
          # Wait for configuration update to complete
          aws lambda wait function-updated \
            --region ap-south-1 \
            --function-name ResumeForge-prod-resume-upload
          echo "Environment variables updated successfully"

      - name: Update IAM Policies
        run: |
          set -euo pipefail
          
          echo "Updating IAM policies for Lambda execution role..."
          
          # DynamoDB policy
          cat > /tmp/dynamodb-policy.json << 'EOF'
          {
            "Statement": [
              {
                "Action": [
                  "dynamodb:GetItem",
                  "dynamodb:DeleteItem",
                  "dynamodb:PutItem",
                  "dynamodb:Scan",
                  "dynamodb:Query",
                  "dynamodb:UpdateItem",
                  "dynamodb:BatchWriteItem",
                  "dynamodb:BatchGetItem",
                  "dynamodb:DescribeTable",
                  "dynamodb:ConditionCheckItem"
                ],
                "Resource": [
                  "arn:aws:dynamodb:ap-south-1:957650740525:table/ResumeForge",
                  "arn:aws:dynamodb:ap-south-1:957650740525:table/ResumeForge/index/*",
                  "arn:aws:dynamodb:ap-south-1:957650740525:table/ResumeForgeLogs",
                  "arn:aws:dynamodb:ap-south-1:957650740525:table/ResumeForgeLogs/index/*"
                ],
                "Effect": "Allow"
              }
            ]
          }
          EOF
          
          # EventBridge policy
          cat > /tmp/eventbridge-policy.json << 'EOF'
          {
            "Statement": [
              {
                "Effect": "Allow",
                "Action": [
                  "events:PutEvents"
                ],
                "Resource": [
                  "arn:aws:events:ap-south-1:957650740525:event-bus/ResumeForge-prod-resume-forge-orchestration"
                ]
              }
            ]
          }
          EOF
          
          # Apply policies
          aws iam put-role-policy \
            --role-name ResumeForge-ResumeForgeFunctionRole-I1oDcO54aMSa \
            --policy-name ResumeForgeFunctionRolePolicy2 \
            --policy-document file:///tmp/dynamodb-policy.json
          
          aws iam put-role-policy \
            --role-name ResumeForge-ResumeForgeFunctionRole-I1oDcO54aMSa \
            --policy-name ResumeForgeFunctionRoleEventBridgePolicy \
            --policy-document file:///tmp/eventbridge-policy.json
          
          echo "IAM policies updated successfully"

      - name: Update published-cloudfront.json in S3
        run: |
          set -euo pipefail
          
          # Create updated config file
          cat > /tmp/published-cloudfront.json << 'EOF'
          {
            "stackName": "ResumeForge",
            "url": "https://d19m8lzbl1980w.cloudfront.net",
            "distributionId": "E2OWOS9JQQDVU3",
            "updatedAt": "$(date -u +%Y-%m-%dT%H:%M:%S.000Z)",
            "degraded": false,
            "apiGatewayUrl": "https://j3a7m3jz11.execute-api.ap-south-1.amazonaws.com/prod",
            "originBucket": "resume-forge-app-2025",
            "originRegion": "ap-south-1",
            "originPath": "/static/client/prod/latest"
          }
          EOF
          
          # Upload to S3 (if Lambda needs to read it from there)
          aws s3 cp /tmp/published-cloudfront.json \
            s3://${DEPLOY_BUCKET}/config/published-cloudfront.json
          
          echo "CloudFront configuration file updated"

      - name: Terraform Init
        continue-on-error: true
        working-directory: infra/terraform
        env:
          TF_VAR_frontend_bucket: resume-forge-app-2025
          TF_VAR_assets_bucket: resume-forge-data-ats
          TF_VAR_aws_region: ap-south-1
        run: terraform init

      - name: Terraform Apply
        continue-on-error: true
        working-directory: infra/terraform
        env:
          TF_VAR_project: ResumeForge
          TF_VAR_aws_region: ap-south-1
          TF_VAR_frontend_bucket: resume-forge-app-2025
          TF_VAR_assets_bucket: resume-forge-data-ats
        run: terraform apply -auto-approve

      - name: Invalidate CloudFront cache
        continue-on-error: true
        run: |
          set -euo pipefail
          
          distribution_id="E2OWOS9JQQDVU3"
          
          if [ -z "$distribution_id" ]; then
            echo "No CloudFront distribution ID found; skipping invalidation" >&2
            exit 1
          fi
          
          aws cloudfront create-invalidation \
            --distribution-id "$distribution_id" \
            --paths "/*"
          
          echo "CloudFront cache invalidation triggered for distribution: $distribution_id"

      - name: Deployment Summary
        run: |
          echo "=========================================="
          echo "Deployment completed successfully!"
          echo "=========================================="
          echo "Frontend URL: https://d19m8lzbl1980w.cloudfront.net"
          echo "API Base URL: https://j3a7m3jz11.execute-api.ap-south-1.amazonaws.com/prod"
          echo "Region: ap-south-1"
          echo "=========================================="
          echo "Lambda Functions Updated:"
          echo "  - ResumeForge-prod-resume-upload"
          echo "  - ResumeForge-prod-workflow-generate"
          echo "  - ResumeForge-prod-workflow-score"
          echo "  - ResumeForge-prod-workflow-combine"
          echo "  - ResumeForge-prod-workflow-enhancement-section"
          echo "=========================================="
