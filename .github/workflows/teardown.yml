name: Teardown Infrastructure

on:
  workflow_dispatch:
    inputs:
      confirm_destroy:
        description: 'Type "DESTROY" to confirm deletion of all resources'
        required: true
        default: 'NO'

jobs:
  destroy:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    if: ${{ github.event.inputs.confirm_destroy == 'DESTROY' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION || 'ap-south-1' }}

      - name: Ensure Buckets Exist (Fix for Terraform Data Sources)
        env:
          FRONTEND_BUCKET: ${{ secrets.FRONTEND_BUCKET || 'resume-forge-app-v2-2025' }}
          DEPLOY_BUCKET: ${{ secrets.DEPLOY_BUCKET || 'resume-forge-data-v2-ats' }}
          AWS_DEFAULT_REGION: ap-south-1
        run: |
          set +e
          echo "Temporarily recreating buckets if missing to satisfy Terraform data sources..."
          
          retry_create_bucket() {
            local bucket=$1
            local attempts=0
            local max_attempts=20
            
            while [ $attempts -lt $max_attempts ]; do
              if aws s3 ls "s3://$bucket" >/dev/null 2>&1; then
                echo "Bucket $bucket exists."
                return 0
              fi
              
              echo "Attempting to create bucket $bucket (Attempt $((attempts+1)))..."
              if aws s3 mb "s3://$bucket" --region ap-south-1; then
                echo "Bucket $bucket created."
                return 0
              else
                echo "Creation failed. Waiting 15s for pending deletions/consistency..."
                sleep 15
                attempts=$((attempts+1))
              fi
            done
            return 1
          }

          retry_create_bucket "$FRONTEND_BUCKET" || echo "WARNING: Failed to recreate $FRONTEND_BUCKET for TF state"
          retry_create_bucket "$DEPLOY_BUCKET" || echo "WARNING: Failed to recreate $DEPLOY_BUCKET for TF state"
          
          echo "Buckets checked/attempted."

      - name: Sanitize Terraform State
        working-directory: infra/terraform
        env:
          TF_VAR_frontend_bucket: resume-forge-app-2025
          TF_VAR_assets_bucket: resume-forge-data-ats
          TF_VAR_aws_region: ap-south-1
          TF_VAR_project: ResumeForge
        run: |
          set +e
          terraform init -reconfigure
          
          echo "Removing problematic policies from state to avoid 301 errors..."
          terraform state rm aws_s3_bucket_policy.frontend || echo "Frontend policy not in state"
          # Also remove assets policy if it exists
          terraform state rm aws_s3_bucket_policy.assets || echo "Assets policy not in state"
          
          echo "State sanitized."

      - name: Delete CLI-Managed Resources (Orphans)
        env:
           AWS_DEFAULT_REGION: ap-south-1
        run: |
          set +e 
          
          FUNCTION_NAME="ResumeForge-DynamoDBStreamProcessor"
          TABLE_NAME="ResumeForgeLogs"
          
          echo "Cleaning up manual resources..."
          
          # 1. Delete Event Source Mappings
          UUIDS=$(aws lambda list-event-source-mappings --function-name "$FUNCTION_NAME" --region ap-south-1 --query "EventSourceMappings[*].UUID" --output text)
          for UUID in $UUIDS; do
            if [ "$UUID" != "None" ] && [ -n "$UUID" ]; then
                aws lambda delete-event-source-mapping --uuid "$UUID" --region ap-south-1
            fi
          done
          
          # 2. Delete Lambda Function
          aws lambda delete-function --function-name "$FUNCTION_NAME" --region ap-south-1 || echo "Function already deleted"
          
          # 3. Delete DynamoDB Table
          aws dynamodb delete-table --table-name "$TABLE_NAME" --region ap-south-1 || echo "Table already deleted"

      - name: Terraform Destroy
        working-directory: infra/terraform
        env:
          TF_VAR_frontend_bucket: resume-forge-app-2025
          TF_VAR_assets_bucket: resume-forge-data-ats
          TF_VAR_aws_region: ap-south-1
          TF_VAR_project: ResumeForge
        run: |
          terraform init
          terraform destroy -auto-approve

      - name: Final S3 Cleanup
        env:
          FRONTEND_BUCKET: ${{ secrets.FRONTEND_BUCKET || 'resume-forge-app-2025' }}
          DEPLOY_BUCKET: ${{ secrets.DEPLOY_BUCKET || 'resume-forge-data-ats' }}
        run: |
          set +e
          echo "Performing final S3 cleanup..."
          
          # Delete all objects and then the bucket
          echo "Deleting $FRONTEND_BUCKET..."
          aws s3 rm "s3://$FRONTEND_BUCKET" --recursive
          aws s3 rb "s3://$FRONTEND_BUCKET" --force
          
          echo "Deleting $DEPLOY_BUCKET..."
          aws s3 rm "s3://$DEPLOY_BUCKET" --recursive
          aws s3 rb "s3://$DEPLOY_BUCKET" --force
